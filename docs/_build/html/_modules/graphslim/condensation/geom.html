<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>graphslim.condensation.geom &mdash; GraphSlim documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1"/>
    <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094"/>


    <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
    <![endif]-->

    <script src="../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script data-url_root="../../../" id="documentation_options"
            src="../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html"/>
    <link rel="search" title="Search" href="../../../search.html"/>
</head>

<body class="wy-body-for-nav">
<div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
        <div class="wy-side-scroll">
            <div class="wy-side-nav-search">


                <a href="../../../index.html" class="icon icon-home">
                    GraphSlim
                </a>
                <div role="search">
                    <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
                        <input type="text" name="q" placeholder="Search docs" aria-label="Search docs"/>
                        <input type="hidden" name="check_keywords" value="yes"/>
                        <input type="hidden" name="area" value="default"/>
                    </form>
                </div>
            </div>
            <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
                <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal"
                                              href="../../../installation.html">Installation</a></li>
                </ul>
                <p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quick Start</a>
                    </li>
                </ul>
                <p class="caption" role="heading"><span class="caption-text">Dataset</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../../source/graphslim.dataset.html">graphslim.dataset
                        package</a></li>
                </ul>
                <p class="caption" role="heading"><span class="caption-text">Models</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../../source/graphslim.models.html">graphslim.models
                        package</a></li>
                </ul>
                <p class="caption" role="heading"><span class="caption-text">Method</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal"
                                              href="../../../source/graphslim.coarsening.html">graphslim.coarsening
                        package</a></li>
                    <li class="toctree-l1"><a class="reference internal"
                                              href="../../../source/graphslim.condensation.html">graphslim.condensation
                        package</a></li>
                    <li class="toctree-l1"><a class="reference internal"
                                              href="../../../source/graphslim.sparsification.html">graphslim.sparsification
                        package</a></li>
                </ul>
                <p class="caption" role="heading"><span class="caption-text">Evaluation</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal"
                                              href="../../../source/graphslim.evaluation.html">graphslim.evaluation
                        package</a></li>
                </ul>

            </div>
        </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <nav class="wy-nav-top" aria-label="Mobile navigation menu">
            <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
            <a href="../../../index.html">GraphSlim</a>
        </nav>

        <div class="wy-nav-content">
            <div class="rst-content">
                <div role="navigation" aria-label="Page navigation">
                    <ul class="wy-breadcrumbs">
                        <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
                        <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
                        <li class="breadcrumb-item active">graphslim.condensation.geom</li>
                        <li class="wy-breadcrumbs-aside">
                        </li>
                    </ul>
                    <hr/>
                </div>
                <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
                    <div itemprop="articleBody">

                        <h1>Source code for graphslim.condensation.geom</h1>
                        <div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">trange</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">from</span> <span class="nn">graphslim.condensation.gcond_base</span> <span
                                class="kn">import</span> <span class="n">GCondBase</span>
<span class="kn">from</span> <span class="nn">graphslim.dataset.utils</span> <span class="kn">import</span> <span
                                class="n">save_reduced</span>
<span class="kn">from</span> <span class="nn">graphslim.condensation.utils</span> <span class="kn">import</span> <span
                                class="n">sort_training_nodes</span><span class="p">,</span> <span class="n">sort_training_nodes_in</span><span
                                class="p">,</span> <span class="n">training_scheduler</span>
<span class="kn">from</span> <span class="nn">graphslim.evaluation.utils</span> <span class="kn">import</span> <span
                                class="n">verbose_time_memory</span>
<span class="kn">from</span> <span class="nn">graphslim.sparsification</span> <span class="kn">import</span> <span
                                class="o">*</span>
<span class="kn">from</span> <span class="nn">graphslim.utils</span> <span class="kn">import</span> <span
                                class="o">*</span>
<span class="kn">from</span> <span class="nn">graphslim.models.reparam_module</span> <span
                                class="kn">import</span> <span class="n">ReparamModule</span>
<span class="kn">from</span> <span class="nn">graphslim.models</span> <span class="kn">import</span> <span
                                class="o">*</span>


<div class="viewcode-block" id="GEOM"><a class="viewcode-back"
                                         href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM">[docs]</a><span
        class="k">class</span> <span class="nc">GEOM</span><span class="p">(</span><span class="n">GCondBase</span><span
        class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span
            class="p">,</span> <span class="n">setting</span><span class="p">,</span> <span class="n">data</span><span
            class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">**</span><span
            class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GEOM</span><span class="p">,</span> <span
            class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span
            class="p">(</span><span class="n">setting</span><span class="p">,</span> <span class="n">data</span><span
            class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">**</span><span
            class="n">kwargs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">args</span><span class="o">.</span><span
            class="n">teacher_epochs</span> <span class="o">+</span> <span class="mi">100</span> <span
            class="o">&gt;=</span> <span class="n">args</span><span class="o">.</span><span
            class="n">expert_epochs</span>
        <span class="n">args</span><span class="o">.</span><span class="n">condense_model</span> <span
            class="o">=</span> <span class="s1">&#39;GCN&#39;</span>
        <span class="c1"># if run init experiment, please comment this</span>
        <span class="c1"># args.init = &#39;kcenter&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span> <span
            class="o">=</span> <span class="s1">&#39;../geom_buffer/</span><span class="si">{}</span><span
            class="s1">_</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span
            class="s1">_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span
            class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">dataset</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span
            class="n">attack</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span
            class="n">ptb_r</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span
            class="n">seed</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span
            class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span
            class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span
            class="p">)</span>

<div class="viewcode-block" id="GEOM.reduce"><a class="viewcode-back"
                                                href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.reduce">[docs]</a>    <span
        class="nd">@verbose_time_memory</span>
    <span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span
            class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">verbose</span><span
            class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">args</span>
        <span class="n">args</span><span class="o">.</span><span class="n">num_experts</span> <span
            class="o">=</span> <span class="mi">20</span>  <span class="c1"># 200</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span
            class="n">no_buff</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=================Begin buffer===============&quot;</span><span
            class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">buffer_cl</span><span class="p">(</span><span
            class="n">data</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=================Finish buffer===============&quot;</span><span
            class="p">)</span>

        <span class="n">flag</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
            <span class="n">flag</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">args</span><span class="o">.</span><span class="n">soft_label</span> <span
            class="o">=</span> <span class="kc">False</span>
        <span class="n">feat_init</span><span class="p">,</span> <span class="n">adj_init</span> <span
            class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span
            class="p">(</span><span class="n">with_adj</span><span class="o">=</span><span class="kc">True</span><span
            class="p">)</span>
        <span class="k">if</span> <span class="n">flag</span><span class="p">:</span>
            <span class="n">args</span><span class="o">.</span><span class="n">soft_label</span> <span
            class="o">=</span> <span class="kc">True</span>

        <span class="n">feat_init</span><span class="p">,</span> <span class="n">adj_init</span><span class="p">,</span> <span
            class="n">labels_init</span> <span class="o">=</span> <span class="n">to_tensor</span><span
            class="p">(</span><span class="n">feat_init</span><span class="p">,</span> <span
            class="n">adj_init</span><span class="p">,</span>
                                                     <span class="n">label</span><span class="o">=</span><span
            class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span><span
            class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feat_syn</span><span class="o">.</span><span
            class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span
            class="n">feat_init</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span> <span
            class="o">=</span> <span class="n">labels_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adj_syn_init</span> <span class="o">=</span> <span
            class="n">adj_init</span>

        <span class="n">file_idx</span><span class="p">,</span> <span class="n">expert_idx</span><span
            class="p">,</span> <span class="n">expert_files</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">expert_load</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
            <span class="n">model_4_soft</span> <span class="o">=</span> <span class="nb">eval</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">condense_model</span><span class="p">)(</span><span class="n">data</span><span
            class="o">.</span><span class="n">feat_train</span><span class="o">.</span><span class="n">shape</span><span
            class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span
            class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">data</span><span
            class="o">.</span><span class="n">nclass</span><span class="p">,</span> <span class="n">args</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span>

            <span class="n">model_4_soft</span> <span class="o">=</span> <span class="n">ReparamModule</span><span
            class="p">(</span><span class="n">model_4_soft</span><span class="p">)</span>

            <span class="n">model_4_soft</span><span class="o">.</span><span class="n">eval</span><span
            class="p">()</span>
            <span class="n">Temp_params</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">buffer</span><span class="p">[</span><span class="mi">0</span><span
            class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">Initialize_Labels_params</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p</span><span
            class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span
            class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span
            class="n">p</span> <span class="ow">in</span> <span class="n">Temp_params</span><span
            class="p">],</span> <span class="mi">0</span><span class="p">)</span>

            <span class="n">adj_syn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">feat_syn</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span
            class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span>
            <span class="n">adj_syn_cal_norm</span> <span class="o">=</span> <span class="n">normalize_adj_tensor</span><span
            class="p">(</span><span class="n">adj_syn</span><span class="p">,</span> <span class="n">sparse</span><span
            class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">adj_syn_input</span> <span class="o">=</span> <span class="n">adj_syn_cal_norm</span>

            <span class="n">feat_4_soft</span><span class="p">,</span> <span class="n">adj_4_soft</span> <span
            class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_syn</span><span
            class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">copy</span><span
            class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
                <span class="n">adj_syn_input</span><span class="o">.</span><span class="n">detach</span><span
            class="p">())</span>
            <span class="n">label_soft</span> <span class="o">=</span> <span class="n">model_4_soft</span><span
            class="o">.</span><span class="n">forward</span><span class="p">(</span><span
            class="n">feat_4_soft</span><span class="p">,</span> <span class="n">adj_4_soft</span><span
            class="p">,</span> <span class="n">flat_param</span><span class="o">=</span><span class="n">Initialize_Labels_params</span><span
            class="p">)</span>

            <span class="n">max_pred</span><span class="p">,</span> <span class="n">pred_lab</span> <span
            class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span
            class="p">(</span><span class="n">label_soft</span><span class="p">,</span> <span class="n">dim</span><span
            class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span
            class="p">(</span><span class="n">labels_init</span><span class="o">.</span><span
            class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">pred_lab</span><span class="p">[</span><span
            class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">labels_init</span><span
            class="p">[</span><span class="n">i</span><span class="p">]:</span>
                    <span class="n">label_soft</span><span class="p">[</span><span class="n">i</span><span
            class="p">][</span><span class="n">labels_init</span><span class="p">[</span><span class="n">i</span><span
            class="p">]]</span> <span class="o">=</span> <span class="n">max_pred</span><span class="p">[</span><span
            class="n">i</span><span class="p">]</span>
                    <span class="c1"># label_soft[i].fill_(0)</span>
                    <span class="c1"># label_soft[i][labels_init[i]] = 1</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span> <span
            class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span
            class="p">(</span><span class="n">label_soft</span><span class="o">.</span><span
            class="n">detach</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span
            class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span><span
            class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span> <span
            class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">labels_syn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># acc = np.sum(np.equal(np.argmax(label_soft.cpu().data.numpy(), axis=-1), labels_init.cpu().data.numpy()))</span>
            <span class="c1"># print(&#39;InitialAcc:{}&#39;.format(acc / len(self.labels_syn)))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_label</span> <span
            class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span
            class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span><span class="p">],</span> <span class="n">lr</span><span
            class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr_y</span><span
            class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span
            class="p">)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">setting</span> <span
            class="o">==</span> <span class="s1">&#39;ind&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tem</span> <span class="o">=</span> <span
            class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">tem</span><span class="p">)</span><span
            class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span
            class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span
            class="p">(</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">optimizer_tem</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span
            class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">tem</span><span
            class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span
            class="o">.</span><span class="n">lr_tem</span><span class="p">)</span>
            <span class="c1"># -------------------------------------softlabel-------------------------------------------------------end-----------------------------------------------------------------#</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels_syn</span> <span
            class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span
            class="n">labels</span><span class="o">=</span><span class="n">labels_init</span><span
            class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">syn_lr</span> <span class="o">=</span> <span
            class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">lr_student</span><span class="p">)</span><span
            class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">optim_lr</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">syn_lr</span> <span
            class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">syn_lr</span><span
            class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span
            class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span
            class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">optimizer_lr</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span
            class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">syn_lr</span><span
            class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span
            class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span
            class="p">)</span>

        <span class="n">best_val</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">bar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">bar</span><span
            class="p">:</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">setting</span> <span
            class="o">==</span> <span class="s1">&#39;ind&#39;</span> <span class="ow">and</span> <span
            class="n">args</span><span class="o">.</span><span class="n">soft_label</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tem</span> <span
            class="o">&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">maxtem</span><span
            class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tem</span> <span
            class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">maxtem</span><span
            class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span
            class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span
            class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">optimizer_tem</span><span class="o">.</span><span class="n">lr</span> <span
            class="o">=</span> <span class="mf">0.0</span>

            <span class="n">model</span> <span class="o">=</span> <span class="nb">eval</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">condense_model</span><span class="p">)(</span><span class="n">data</span><span
            class="o">.</span><span class="n">feat_train</span><span class="o">.</span><span class="n">shape</span><span
            class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span
            class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">data</span><span
            class="o">.</span><span class="n">nclass</span><span class="p">,</span> <span class="n">args</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">model_4_clom</span> <span class="o">=</span> <span class="nb">eval</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">condense_model</span><span class="p">)(</span><span class="n">data</span><span
            class="o">.</span><span class="n">feat_train</span><span class="o">.</span><span class="n">shape</span><span
            class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span
            class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">data</span><span
            class="o">.</span><span class="n">nclass</span><span class="p">,</span> <span class="n">args</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span>

            <span class="n">model</span> <span class="o">=</span> <span class="n">ReparamModule</span><span
            class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">model_4_clom</span> <span class="o">=</span> <span class="n">ReparamModule</span><span
            class="p">(</span><span class="n">model_4_clom</span><span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span
            class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span
            class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">size</span><span
            class="p">())</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span
            class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span
            class="p">())])</span>

            <span class="n">expert_trajectory</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">buffer</span><span class="p">[</span><span
            class="n">expert_idx</span><span class="p">]</span>
            <span class="n">expert_idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">expert_idx</span> <span class="o">==</span> <span
            class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">buffer</span><span class="p">):</span>
                <span class="n">expert_idx</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">file_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">file_idx</span> <span class="o">==</span> <span
            class="nb">len</span><span class="p">(</span><span class="n">expert_files</span><span class="p">):</span>
                    <span class="n">file_idx</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span
            class="p">(</span><span class="n">expert_files</span><span class="p">)</span>
                <span class="c1"># print(&quot;loading file {}&quot;.format(expert_files[file_idx]))</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span
            class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span
            class="p">(</span><span class="n">expert_files</span><span class="p">[</span><span class="n">file_idx</span><span
            class="p">])</span>
                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span
            class="p">)</span>

            <span class="c1"># expanding window</span>
            <span class="n">Upper_Bound</span> <span class="o">=</span> <span class="n">args</span><span
            class="o">.</span><span class="n">max_start_epoch_s</span> <span class="o">+</span> <span
            class="n">it</span>
            <span class="n">Upper_Bound</span> <span class="o">=</span> <span class="nb">min</span><span
            class="p">(</span><span class="n">Upper_Bound</span><span class="p">,</span> <span
            class="n">args</span><span class="o">.</span><span class="n">max_start_epoch</span><span class="p">)</span>
            <span class="c1"># print(Upper_Bound)</span>

            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">np</span><span
            class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">min_start_epoch</span><span class="p">,</span> <span class="n">Upper_Bound</span><span
            class="p">)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">optim</span> <span class="o">==</span> <span class="s1">&#39;Adam&#39;</span><span
            class="p">:</span>
                <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">start_epoch</span> <span
            class="o">//</span> <span class="mi">10</span>
            <span class="n">starting_params</span> <span class="o">=</span> <span
            class="n">expert_trajectory</span><span class="p">[</span><span class="n">start_epoch</span><span class="p">]</span>

            <span class="c1"># if args.interval_buffer == 1:</span>
            <span class="c1"># print(start_epoch + args.expert_epochs // 10)</span>
            <span class="n">target_params</span> <span class="o">=</span> <span class="n">expert_trajectory</span><span
            class="p">[</span><span class="n">start_epoch</span> <span class="o">+</span> <span
            class="n">args</span><span class="o">.</span><span class="n">expert_epochs</span> <span class="o">//</span> <span
            class="mi">10</span><span class="p">]</span>
            <span class="n">target_params</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p</span><span
            class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span
            class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span
            class="n">p</span> <span class="ow">in</span> <span class="n">target_params</span><span class="p">],</span> <span
            class="mi">0</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">beta</span><span class="p">:</span>
                <span class="n">target_params_4_clom</span> <span class="o">=</span> <span
            class="n">expert_trajectory</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span>
                <span class="n">target_params_4_clom</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p</span><span
            class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span
            class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span
            class="n">p</span> <span class="ow">in</span> <span class="n">target_params_4_clom</span><span
            class="p">],</span> <span class="mi">0</span><span class="p">)</span>
                <span class="n">params_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span
            class="n">model_4_clom</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span
            class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="ow">in</span> <span
            class="n">params_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">data</span><span
            class="o">.</span><span class="n">copy_</span><span class="p">(</span><span
            class="n">target_params_4_clom</span><span class="p">)</span>
                <span class="n">model_4_clom</span><span class="o">.</span><span class="n">load_state_dict</span><span
            class="p">(</span><span class="n">params_dict</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_4_clom</span><span
            class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span
            class="o">=</span> <span class="kc">False</span>

            <span class="n">student_params</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span
            class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span
            class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span
            class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span
            class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span
            class="n">starting_params</span><span class="p">],</span> <span class="mi">0</span><span
            class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span
            class="kc">True</span><span class="p">)]</span>

            <span class="n">starting_params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">cat</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span
            class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span
            class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span
            class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span
            class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span
            class="ow">in</span> <span class="n">starting_params</span><span class="p">],</span> <span
            class="mi">0</span><span class="p">)</span>

            <span class="n">param_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">param_dist_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># print(&#39;it:{}--feat_max = {:.4f}, feat_min = {:.4f}&#39;.format(it, torch.max(self.feat_syn),</span>
            <span class="c1">#                                                                   torch.min(self.feat_syn)))</span>

            <span class="k">if</span> <span class="n">it</span> <span class="o">==</span> <span
            class="mi">0</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span
            class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;reddit&#39;</span><span
            class="p">]</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span
            class="n">reduction_rate</span> <span class="o">&lt;</span> <span class="mf">0.075</span><span
            class="p">:</span>
                <span class="n">feat_syn</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">feat_syn</span>
                <span class="n">adj_syn_norm</span> <span class="o">=</span> <span class="n">normalize_adj_tensor</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">adj_syn_init</span><span class="p">,</span> <span class="n">sparse</span><span
            class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">adj_syn_input</span> <span class="o">=</span> <span class="n">adj_syn_norm</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">feat_syn</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">feat_syn</span>
                <span class="n">adj_syn</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">feat_syn</span><span
            class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span
            class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span
            class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">adj_syn_cal_norm</span> <span class="o">=</span> <span
            class="n">normalize_adj_tensor</span><span class="p">(</span><span class="n">adj_syn</span><span
            class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span
            class="p">)</span>
                <span class="n">adj_syn_input</span> <span class="o">=</span> <span class="n">adj_syn_cal_norm</span>

            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span
            class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">syn_steps</span><span class="p">):</span>
                <span class="n">forward_params</span> <span class="o">=</span> <span
            class="n">student_params</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span>
                <span class="n">output_syn</span> <span class="o">=</span> <span class="n">model</span><span
            class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">feat_syn</span><span
            class="p">,</span> <span class="n">adj_syn_input</span><span class="p">,</span> <span
            class="n">flat_param</span><span class="o">=</span><span class="n">forward_params</span><span
            class="p">)</span>

                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
                    <span class="n">loss_syn</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span
            class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span
            class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span
            class="kc">True</span><span class="p">)(</span><span class="n">output_syn</span><span
            class="p">,</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">labels_syn</span><span class="p">)</span>
                    <span class="c1"># acc_syn = accuracy(output_syn, torch.argmax(self.labels_syn, dim=1))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss_syn</span> <span class="o">=</span> <span class="n">F</span><span
            class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span
            class="n">output_syn</span><span class="p">,</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span><span class="p">)</span>
                    <span class="c1"># acc_syn = accuracy(output_syn, self.labels_syn)</span>

                <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span
            class="p">(</span><span class="n">loss_syn</span><span class="p">,</span> <span
            class="n">student_params</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">],</span> <span class="n">create_graph</span><span
            class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span
            class="p">]</span>

                <span class="n">student_params</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span
            class="n">student_params</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">syn_lr</span> <span class="o">*</span> <span class="n">grad</span>
                <span class="c1"># if step % 500 == 0:</span>
                <span class="c1">#     output_test = model.forward(features_tensor, adj_tensor_norm, flat_param=student_params[-1])</span>
                <span class="c1">#     acc_test = accuracy(output_test[data.idx_test], labels_tensor[[data.idx_test]])</span>
                <span class="c1"># print(&#39;loss = {:.4f},acc_syn = {:.4f},acc_test = {:.4f}&#39;.format(loss_syn.item(),</span>
                <span class="c1">#                                                                        acc_syn.item(),</span>
                <span class="c1">#                                                                        acc_test.item()))</span>

            <span class="n">param_loss</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">param_dist</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">param_loss</span> <span class="o">+=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">norm</span><span class="p">(</span><span
            class="n">student_params</span><span class="p">[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span
            class="n">target_params</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">param_dist</span> <span class="o">+=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">starting_params</span> <span
            class="o">-</span> <span class="n">target_params</span><span class="p">,</span> <span
            class="mi">2</span><span class="p">)</span>

            <span class="n">param_loss_list</span><span class="o">.</span><span class="n">append</span><span
            class="p">(</span><span class="n">param_loss</span><span class="p">)</span>
            <span class="n">param_dist_list</span><span class="o">.</span><span class="n">append</span><span
            class="p">(</span><span class="n">param_dist</span><span class="p">)</span>

            <span class="n">param_loss</span> <span class="o">/=</span> <span class="n">num_params</span>
            <span class="n">param_dist</span> <span class="o">/=</span> <span class="n">num_params</span>

            <span class="n">param_loss</span> <span class="o">/=</span> <span class="n">param_dist</span>

            <span class="n">grand_loss</span> <span class="o">=</span> <span class="n">param_loss</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">beta</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">total_loss</span> <span class="o">=</span> <span class="n">grand_loss</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_clom</span> <span class="o">=</span> <span class="n">model_4_clom</span><span
            class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">feat_syn</span><span
            class="p">,</span> <span class="n">adj_syn_input</span><span class="p">,</span>
                                                   <span class="n">flat_param</span><span class="o">=</span><span
            class="n">target_params_4_clom</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s2">&quot;ind&quot;</span><span
            class="p">:</span>
                        <span class="n">loss_clom</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span
            class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span
            class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span
            class="kc">True</span><span class="p">)(</span><span class="n">output_clom</span> <span
            class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tem</span><span
            class="p">,</span>
                                                                                               <span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span> <span class="o">/</span> <span
            class="bp">self</span><span class="o">.</span><span class="n">tem</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">loss_clom</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span
            class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span
            class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span
            class="kc">True</span><span class="p">)(</span><span class="n">output_clom</span><span class="p">,</span>
                                                                                               <span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss_clom</span> <span class="o">=</span> <span class="n">F</span><span
            class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span
            class="n">output_clom</span><span class="p">,</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">=</span> <span class="n">grand_loss</span> <span
            class="o">+</span> <span class="n">args</span><span class="o">.</span><span class="n">beta</span> <span
            class="o">*</span> <span class="n">loss_clom</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_feat</span><span
            class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_label</span><span
            class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s2">&quot;ind&quot;</span><span
            class="p">:</span>
                    <span class="n">optimizer_tem</span><span class="o">.</span><span class="n">zero_grad</span><span
            class="p">()</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">optim_lr</span><span
            class="p">:</span>
                <span class="n">optimizer_lr</span><span class="o">.</span><span class="n">zero_grad</span><span
            class="p">()</span>

            <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span
            class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_feat</span><span
            class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">soft_label</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_label</span><span
            class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;ind&#39;</span><span
            class="p">:</span>
                    <span class="n">optimizer_tem</span><span class="o">.</span><span class="n">zero_grad</span><span
            class="p">()</span>
            <span class="c1"># print(&#39;torch.sum(self.feat_syn) = {}&#39;.format(torch.sum(self.feat_syn)))</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">optim_lr</span><span
            class="p">:</span>
                <span class="n">optimizer_lr</span><span class="o">.</span><span class="n">step</span><span
            class="p">()</span>

            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">isnan</span><span class="p">(</span><span class="n">total_loss</span><span
            class="p">)</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">isnan</span><span class="p">(</span><span class="n">grand_loss</span><span class="p">):</span>
                <span class="k">break</span>  <span class="c1"># Break out of the loop if either is NaN</span>
            <span class="c1"># bar.set_postfix_str(</span>
            <span class="c1">#     f&quot;File ID = {file_idx} Total_Loss = {total_loss.item():.4f} Syn_Lr = {self.syn_lr.item():.4f}&quot;)</span>
            <span class="c1"># print(</span>
            <span class="c1">#     &quot;Iteration {}: Total_Loss = {:.4f}, Grand_Loss={:.4f}, Start_Epoch= {}, Student_LR = {:6f}&quot;.format(</span>
            <span class="c1">#         it,</span>
            <span class="c1">#         total_loss.item(),</span>
            <span class="c1">#         grand_loss.item(),</span>
            <span class="c1">#         start_epoch,</span>
            <span class="c1">#         self.syn_lr.item()))</span>

            <span class="c1"># eval_it_pool = np.arange(0, args.epochs + 1, args.eval_interval).tolist()</span>
            <span class="k">if</span> <span class="n">it</span> <span class="ow">in</span> <span
            class="n">args</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">:</span>
                <span class="n">feat_syn_save</span><span class="p">,</span> <span class="n">adj_syn_save</span><span
            class="p">,</span> <span class="n">label_syn_save</span> <span class="o">=</span> <span
            class="bp">self</span><span class="o">.</span><span class="n">synset_save</span><span class="p">()</span>
                <span class="n">data</span><span class="o">.</span><span class="n">adj_syn</span><span
            class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">feat_syn</span><span
            class="p">,</span> <span class="n">data</span><span class="o">.</span><span
            class="n">labels_syn</span> <span class="o">=</span> <span class="n">adj_syn_save</span><span
            class="p">,</span> <span class="n">feat_syn_save</span><span class="p">,</span> <span class="n">label_syn_save</span>
                <span class="n">best_val</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">intermediate_evaluation</span><span class="p">(</span><span class="n">best_val</span><span
            class="p">,</span> <span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span
            class="p">())</span>

            <span class="c1"># if it % 1000 == 0 or it == args.ITER:</span>
            <span class="c1">#     feat_syn_save, adj_syn_save, label_syn_save = self.synset_save()</span>
            <span class="c1">#     torch.save(adj_syn_save,</span>
            <span class="c1">#                f&#39;{args.log_dir}/adj_{args.dataset}_{args.reduction_rate}_{it}_{args.seed_student}_ours.pt&#39;)</span>
            <span class="c1">#     torch.save(feat_syn_save,</span>
            <span class="c1">#                f&#39;{args.log_dir}/feat_{args.dataset}_{args.reduction_rate}_{it}_{args.seed_student}_ours.pt&#39;)</span>
            <span class="c1">#     torch.save(label_syn_save,</span>
            <span class="c1">#                f&#39;{args.log_dir}/label_{args.dataset}_{args.reduction_rate}_{it}_{args.seed_student}_ours.pt&#39;)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">student_params</span><span
            class="p">:</span>
                <span class="k">del</span> <span class="n">_</span>

            <span class="c1"># writer.add_scalar(&#39;grand_loss_curve&#39;, grand_loss.item(), it)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span
            class="n">empty_cache</span><span class="p">()</span>

            <span class="c1"># gc.collect()</span>
        <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="GEOM.buffer_cl"><a class="viewcode-back"
                                                   href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.buffer_cl">[docs]</a>    <span
        class="k">def</span> <span class="nf">buffer_cl</span><span class="p">(</span><span class="bp">self</span><span
        class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">args</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;trans&#39;</span><span
            class="p">:</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span
            class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span
            class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span
            class="n">feat_full</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span
            class="n">adj_full</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span
            class="n">data</span><span class="o">.</span><span class="n">labels_full</span><span
            class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span
            class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span
            class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span
            class="n">feat_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span
            class="n">adj_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span
            class="n">data</span><span class="o">.</span><span class="n">labels_train</span><span class="p">,</span>
                                              <span class="n">device</span><span class="o">=</span><span
            class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">adj</span> <span class="o">=</span> <span class="n">normalize_adj_tensor</span><span
            class="p">(</span><span class="n">adj</span><span class="p">,</span> <span class="n">sparse</span><span
            class="o">=</span><span class="n">is_sparse_tensor</span><span class="p">(</span><span
            class="n">adj</span><span class="p">))</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span
            class="n">device</span>

        <span class="n">trajectories</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">adj_coo</span> <span class="o">=</span> <span class="n">adj</span><span class="o">.</span><span
            class="n">to_torch_sparse_coo_tensor</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s2">&quot;trans&quot;</span><span class="p">:</span>
            <span class="n">sorted_trainset</span> <span class="o">=</span> <span
            class="n">sort_training_nodes</span><span class="p">(</span><span class="n">data</span><span
            class="p">,</span> <span class="n">adj_coo</span><span class="p">,</span> <span class="n">labels</span><span
            class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sorted_trainset</span> <span class="o">=</span> <span
            class="n">sort_training_nodes_in</span><span class="p">(</span><span class="n">data</span><span
            class="p">,</span> <span class="n">adj_coo</span><span class="p">,</span> <span class="n">labels</span><span
            class="p">)</span>

        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span
            class="n">trange</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">num_experts</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="nb">eval</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">condense_model</span><span class="p">)(</span><span class="n">features</span><span
            class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span
            class="p">],</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden</span><span
            class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">nclass</span><span
            class="p">,</span> <span class="n">args</span><span class="p">)</span><span class="o">.</span><span
            class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">model</span><span class="o">.</span><span class="n">initialize</span><span
            class="p">()</span>

            <span class="n">model_parameters</span> <span class="o">=</span> <span class="nb">list</span><span
            class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span
            class="p">())</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">optim</span> <span class="o">==</span> <span class="s1">&#39;Adam&#39;</span><span
            class="p">:</span>
                <span class="n">optimizer_model</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span
            class="p">(</span><span class="n">model_parameters</span><span class="p">,</span> <span
            class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span
            class="n">lr_teacher</span><span class="p">,</span> <span class="n">weight_decay</span><span
            class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">wd_teacher</span><span
            class="p">)</span>
            <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">optim</span> <span
            class="o">==</span> <span class="s1">&#39;SGD&#39;</span><span class="p">:</span>
                <span class="n">optimizer_model</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span
            class="p">(</span><span class="n">model_parameters</span><span class="p">,</span> <span
            class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span
            class="n">lr_teacher</span><span class="p">,</span> <span class="n">momentum</span><span
            class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">mom_teacher</span><span
            class="p">,</span>
                                                  <span class="n">weight_decay</span><span class="o">=</span><span
            class="n">args</span><span class="o">.</span><span class="n">wd_teacher</span><span class="p">)</span>

            <span class="n">timestamps</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">timestamps</span><span class="o">.</span><span class="n">append</span><span
            class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">detach</span><span
            class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span
            class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span
            class="o">.</span><span class="n">parameters</span><span class="p">()])</span>

            <span class="n">lam</span> <span class="o">=</span> <span class="nb">float</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">lam</span><span
            class="p">)</span>
            <span class="n">T</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">args</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span
            class="n">lam</span>
            <span class="n">args</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span
            class="n">T</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">args</span><span
            class="o">.</span><span class="n">scheduler</span>

            <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">teacher_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span
            class="p">()</span>
                <span class="n">optimizer_model</span><span class="o">.</span><span class="n">zero_grad</span><span
            class="p">()</span>

                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span
            class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span
            class="p">,</span> <span class="n">adj</span><span class="p">)</span>

                <span class="n">size</span> <span class="o">=</span> <span class="n">training_scheduler</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">lam</span><span
            class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span
            class="n">scheduler</span><span class="p">)</span>

                <span class="n">training_subset</span> <span class="o">=</span> <span
            class="n">sorted_trainset</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span
            class="n">size</span> <span class="o">*</span> <span class="n">sorted_trainset</span><span
            class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span
            class="p">])]</span>

                <span class="n">loss_buffer</span> <span class="o">=</span> <span class="n">F</span><span
            class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span
            class="p">[</span><span class="n">training_subset</span><span class="p">],</span> <span
            class="n">labels</span><span class="p">[</span><span class="n">training_subset</span><span
            class="p">])</span>

                <span class="n">loss_buffer</span><span class="o">.</span><span class="n">backward</span><span
            class="p">()</span>
                <span class="n">optimizer_model</span><span class="o">.</span><span class="n">step</span><span
            class="p">()</span>

                <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span
            class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span
            class="n">e</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">timestamps</span><span class="o">.</span><span class="n">append</span><span
            class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">detach</span><span
            class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span
            class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span
            class="o">.</span><span class="n">parameters</span><span class="p">()])</span>

            <span class="n">trajectories</span><span class="o">.</span><span class="n">append</span><span
            class="p">(</span><span class="n">timestamps</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span
            class="n">trajectories</span><span class="p">)</span> <span class="o">==</span> <span
            class="mi">10</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">while</span> <span class="n">os</span><span class="o">.</span><span
            class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span
            class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span
            class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span
            class="n">buf_dir</span><span class="p">,</span> <span class="s2">&quot;replay_buffer_</span><span
            class="si">{}</span><span class="s2">.pt&quot;</span><span class="o">.</span><span
            class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))):</span>
                    <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving </span><span
            class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span
            class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span
            class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">buf_dir</span><span class="p">,</span> <span class="s2">&quot;replay_buffer_</span><span
            class="si">{}</span><span class="s2">.pt&quot;</span><span class="o">.</span><span
            class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))))</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span
            class="p">(</span><span class="n">trajectories</span><span class="p">,</span> <span class="n">os</span><span
            class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span
            class="p">,</span> <span class="s2">&quot;replay_buffer_</span><span class="si">{}</span><span class="s2">.pt&quot;</span><span
            class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span
            class="p">)))</span>
                <span class="n">trajectories</span> <span class="o">=</span> <span class="p">[]</span></div>

<div class="viewcode-block" id="GEOM.expert_load"><a class="viewcode-back"
                                                     href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.expert_load">[docs]</a>    <span
        class="k">def</span> <span class="nf">expert_load</span><span class="p">(</span><span
        class="bp">self</span><span class="p">):</span>
        <span class="n">expert_files</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span
            class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span
            class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span
            class="p">,</span> <span class="s2">&quot;replay_buffer_</span><span class="si">{}</span><span class="s2">.pt&quot;</span><span
            class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span
            class="p">))):</span>
            <span class="n">expert_files</span><span class="o">.</span><span class="n">append</span><span
            class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span
            class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span
            class="o">.</span><span class="n">buf_dir</span><span class="p">,</span> <span class="s2">&quot;replay_buffer_</span><span
            class="si">{}</span><span class="s2">.pt&quot;</span><span class="o">.</span><span
            class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span
            class="p">:</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s2">&quot;No buffers detected at </span><span
            class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span
            class="p">))</span>
        <span class="n">file_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">expert_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span
            class="n">expert_files</span><span class="p">)</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">load</span><span class="p">(</span><span class="n">expert_files</span><span
            class="p">[</span><span class="n">file_idx</span><span class="p">])</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span
            class="n">buffer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span
            class="n">buffer</span>

        <span class="k">return</span> <span class="n">file_idx</span><span class="p">,</span> <span
            class="n">expert_idx</span><span class="p">,</span> <span class="n">expert_files</span></div>

<div class="viewcode-block" id="GEOM.synset_save"><a class="viewcode-back"
                                                     href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.synset_save">[docs]</a>    <span
        class="k">def</span> <span class="nf">synset_save</span><span class="p">(</span><span
        class="bp">self</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">args</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span
            class="n">no_grad</span><span class="p">():</span>
            <span class="n">feat_save</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">feat_syn</span>
            <span class="n">eval_labs</span> <span class="o">=</span> <span class="bp">self</span><span
            class="o">.</span><span class="n">labels_syn</span>

        <span class="n">feat_syn_eval</span><span class="p">,</span> <span class="n">label_syn_eval</span> <span
            class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span
            class="p">(</span><span class="n">feat_save</span><span class="o">.</span><span class="n">detach</span><span
            class="p">()),</span> <span class="n">copy</span><span class="o">.</span><span
            class="n">deepcopy</span><span class="p">(</span>
            <span class="n">eval_labs</span><span class="o">.</span><span class="n">detach</span><span
            class="p">())</span>  <span class="c1"># avoid any unaware modification</span>

        <span class="n">adj_syn_eval</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">eye</span><span class="p">(</span><span
            class="n">feat_syn_eval</span><span class="o">.</span><span class="n">shape</span><span
            class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span
            class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span
            class="p">)</span>

        <span class="k">return</span> <span class="n">feat_syn_eval</span><span class="p">,</span> <span class="n">adj_syn_eval</span><span
            class="p">,</span> <span class="n">label_syn_eval</span></div>

<div class="viewcode-block" id="GEOM.init_coreset_select"><a class="viewcode-back"
                                                             href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.init_coreset_select">[docs]</a>    <span
        class="k">def</span> <span class="nf">init_coreset_select</span><span class="p">(</span><span
        class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">args</span>

        <span class="c1"># random.seed(15)</span>
        <span class="c1"># np.random.seed(15)</span>
        <span class="c1"># torch.manual_seed(15)</span>
        <span class="c1"># torch.cuda.manual_seed(15)</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span
            class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;trans&#39;</span><span
            class="p">:</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span
            class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span
            class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span
            class="n">feat_full</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span
            class="n">adj_full</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span
            class="n">data</span><span class="o">.</span><span class="n">labels_full</span><span
            class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span
            class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">features</span><span class="p">,</span> <span class="n">adj</span><span
            class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span
            class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span
            class="n">feat_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span
            class="n">adj_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span
            class="n">data</span><span class="o">.</span><span class="n">labels_train</span><span class="p">,</span>
                                              <span class="n">device</span><span class="o">=</span><span
            class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">adj</span> <span class="o">=</span> <span class="n">normalize_adj_tensor</span><span
            class="p">(</span><span class="n">adj</span><span class="p">,</span> <span class="n">sparse</span><span
            class="o">=</span><span class="n">is_sparse_tensor</span><span class="p">(</span><span
            class="n">adj</span><span class="p">))</span>
        <span class="n">idx_train</span> <span class="o">=</span> <span class="n">data</span><span
            class="o">.</span><span class="n">idx_train</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span
            class="n">device</span>

        <span class="n">model</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span
            class="n">args</span><span class="o">.</span><span class="n">condense_model</span><span
            class="p">)(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span
            class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span
            class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">data</span><span
            class="o">.</span><span class="n">nclass</span><span class="p">,</span> <span class="n">args</span><span
            class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span
            class="p">)</span>

        <span class="n">optimizer_model</span> <span class="o">=</span> <span class="n">torch</span><span
            class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span
            class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span
            class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span
            class="o">.</span><span class="n">lr_coreset</span><span class="p">,</span> <span
            class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span
            class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span
            class="n">coreset_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">optimizer_model</span><span class="o">.</span><span class="n">zero_grad</span><span
            class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span
            class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span
            class="p">,</span> <span class="n">adj</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">setting</span> <span
            class="o">==</span> <span class="s1">&#39;trans&#39;</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span
            class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span
            class="p">[</span><span class="n">idx_train</span><span class="p">],</span> <span
            class="n">labels</span><span class="p">[</span><span class="n">idx_train</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span
            class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span
            class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_model</span><span class="o">.</span><span class="n">step</span><span
            class="p">()</span>

        <span class="n">embed_out</span> <span class="o">=</span> <span class="n">model</span><span
            class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span
            class="p">,</span> <span class="n">adj</span><span class="p">,</span> <span class="n">normadj</span><span
            class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_layer_features</span><span
            class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="o">-</span><span
            class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span
            class="p">()</span>

        <span class="n">agent</span> <span class="o">=</span> <span class="n">KCenter</span><span
            class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">setting</span><span
            class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">args</span><span
            class="p">)</span>

        <span class="n">idx_selected</span> <span class="o">=</span> <span class="n">agent</span><span
            class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">embed_out</span><span
            class="p">)</span>

        <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span
            class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span
            class="o">.</span><span class="n">buf_dir</span><span class="si">}</span><span class="s1">/idx_</span><span
            class="si">{</span><span class="n">args</span><span class="o">.</span><span class="n">dataset</span><span
            class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">args</span><span
            class="o">.</span><span class="n">reduction_rate</span><span class="si">}</span><span
            class="s1">_kcenter_</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span
            class="n">seed</span><span class="si">}</span><span class="s1">.npy&#39;</span><span class="p">,</span>
                <span class="n">idx_selected</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finish corset selection, saved.&quot;</span><span
            class="p">)</span>

        <span class="k">return</span> <span class="n">idx_selected</span></div>

<div class="viewcode-block" id="GEOM.get_coreset_init"><a class="viewcode-back"
                                                          href="../../../source/graphslim.condensation.html#graphslim.condensation.geom.GEOM.get_coreset_init">[docs]</a>    <span
        class="k">def</span> <span class="nf">get_coreset_init</span><span class="p">(</span><span
        class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span
        class="n">adj</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span
            class="n">args</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Loading from: </span><span
            class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span
            class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span
            class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span class="si">}</span><span
            class="s1">/idx_</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span
            class="n">dataset</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span
            class="n">args</span><span class="o">.</span><span class="n">reduction_rate</span><span
            class="si">}</span><span class="s1">_kcenter_</span><span class="si">{</span><span
            class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="si">}</span><span
            class="s1">.npy&#39;</span><span class="p">))</span>
        <span class="n">idx_selected_train</span> <span class="o">=</span> <span class="n">np</span><span
            class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span
            class="bp">self</span><span class="o">.</span><span class="n">buf_dir</span><span class="si">}</span><span
            class="s1">/idx_</span><span class="si">{</span><span class="n">args</span><span class="o">.</span><span
            class="n">dataset</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span
            class="n">args</span><span class="o">.</span><span class="n">reduction_rate</span><span
            class="si">}</span><span class="s1">_kcenter_</span><span class="si">{</span><span
            class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="si">}</span><span
            class="s1">.npy&#39;</span><span class="p">)</span>
        <span class="n">feat_train</span> <span class="o">=</span> <span class="n">features</span><span
            class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span
            class="n">idx_selected_train</span><span class="p">]</span>
        <span class="n">adj_train</span> <span class="o">=</span> <span class="n">adj</span><span
            class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span
            class="p">(</span><span class="n">idx_selected_train</span><span class="p">,</span> <span class="n">idx_selected_train</span><span
            class="p">)]</span>
        <span class="n">labels_train</span> <span class="o">=</span> <span class="n">labels</span><span
            class="p">[</span><span class="n">idx_selected_train</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">feat_train</span><span class="p">,</span> <span class="n">adj_train</span><span
            class="p">,</span> <span class="n">labels_train</span></div></div>
</pre>
                        </div>

                    </div>
                </div>
                <footer>

                    <hr/>

                    <div role="contentinfo">
                        <p>&#169; Copyright 2024, Melody Group.</p>
                    </div>

                    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
                    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
                    provided by <a href="https://readthedocs.org">Read the Docs</a>.


                </footer>
            </div>
        </div>
    </section>
</div>
<script>
    jQuery(function () {
        SphinxRtdTheme.Navigation.enable(true);
    });
</script>

</body>
</html>